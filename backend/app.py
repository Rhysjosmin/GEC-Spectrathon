import json
from flask import Flask, request
from flask_cors import CORS
from time import sleep

app = Flask(__name__)
cors = CORS(app)


@app.route("/search")
def searchCourse():
    query = request.args.get("query")
    # The user enters the course that he/she want to learn about
    # Checks if the course is present .
    # If present then return the course data/stuff
    # Else ask the user if they want to add a new course
    results = collection.query(
    query_texts=["Fractals"],
    n_results=3,
    include=['documents','distances','metadatas']

    )
    dist = np.average(results['distances'])
    courses = [{"question":obj['question'],{"summary":obj['summary'],'answers':obj['answers'],'correct':obj['correct']}} for obj in results['metadatas'][0]]
    """ 'metadatas': [[{'genre': 'Computer Science & Information Technology'},
   {'genre': 'Medicine'},
   {'genre': 'Chemistry'}]], """
    return {
            "present": dist > 0.3,
            "courses": [
                {"name": "English", "code": "5323he"},
                {"name": "Science", "code": "eury3wye"},
            ],
    }




@app.route("/createCourse")
def createCourse():
    file = request.files['file']
    # fileType
    # if file is content read directly else parse properly
    import spacy
    from collections import Counter
    import language_tool_python


    nlp = spacy.load("en_core_web_sm")
    # similarity = spacy.load('en_core_web_lg')

    topics = ['Physics', 'Chemistry', 'Biology', 'Mathematics', 'Computer Science', 'Medicine', 'Art History', 'Computer Science & Information Technology', 'Law','Statistics']
    content = "This means that as you zoom into a fractal, you'll see smaller copies of the overall shape, repeating infinitely. Fractals are not limited to simple shapes like squares or circles; they can have intricate and infinitely detailed patterns.One of the most famous fractals is the Mandelbrot set, discovered by mathematician Benoit Mandelbrot in the 1970s. The Mandelbrot set is generated by iterating a simple mathematical formula and determining whether the resulting sequence remains bounded or tends to infinity. Points within the Mandelbrot set are colored black, while points outside the set are colored based on how quickly they diverge to infinity.Fractals have applications in various fields, including mathematics, physics, computer science, and art. In mathematics, fractals provide insights into chaos theory, dynamical systems, and nonlinear dynamics. In physics, fractals are used to model irregular shapes in nature, such as coastlines, clouds, and mountains.Fractal geometry also has practical applications in computer graphics, where it is used to generate realistic-looking terrain, textures, and natural phenomena in video games and visual effects.Additionally, fractals inspire artists and designers with their intricate and mesmerizing patterns, leading to the creation of stunning artworks and architectural designs.The number e is defined as the limit of the expression (1 + 1/n)^n as n approaches infinity. This constant, approximately equal to 2.71828, is a fundamental mathematical constant in calculus and analysis. It appears naturally in many mathematical contexts, including exponential growth and decay, compound interest calculations, probability theory, and the study of continuous change. Its significance stems from its role as the base of the natural logarithm function, ln(x), where e^x represents exponential growth or decay at a rate proportional to the value of x. The number e is also transcendental, meaning it is not the root of any non-zero polynomial equation with rational coefficients."

    doc = nlp(content)

    word_counts = Counter()

    for token in doc:
    if token.pos_.startswith("N") and token.is_alpha:
        word = token.text.lower()
        word_counts[word] += 1

    top_nouns = word_counts.most_common(5)

    print("Top 5 Most Frequent Nouns:")
    for word, count in top_nouns:
        print(f"{word}: {count}")

    type(top_nouns)

    sentences = [sent.text for sent in doc.sents]
    sentence_similarities = []

    top_nouns = [token.text for token in doc if token.pos_ == "NOUN"][:5]

    for sentence in sentences:
        sentence_doc = nlp(sentence)
        similarities = [sentence_doc.similarity(nlp(noun)) for noun in top_nouns]
        max_similarity = max(similarities)
        sentence_similarities.append((sentence, max_similarity))

    sentence_similarities.sort(key=lambda x: x[1], reverse=True)

    print("Top 5 Most Similar Sentences are given below:")
    for sentence, similarity in sentence_similarities[:5]:
        print(f"{sentence} (Similarity: {similarity:.2f})")

    # Initialize LanguageTool (optional, comment out if not needed)
    tool = language_tool_python.LanguageTool('en-US')

    # Load the English language model
    # nlp = spacy.load("en_core_web_sm")

    """
    convert_to_questions: function|text
    Converts a sentence into a question based on the English format
    input: Fractals are complex geometric shapes that exhibit self-similarity at different scales
    output: What are complex geometric shapes that exhibit self-similarity at different scales
    """

    def convert_to_question(sentence):
        matches = tool.check(sentence)
        corrected_sentence = language_tool_python.utils.correct(sentence, matches)


        doc = nlp(corrected_sentence)


        question_word = None
        is_followed_by_noun = False
        for i, token in enumerate(doc):
            if token.dep_ in ('nsubj', 'dobj'):
                # Noun subject or object (who/what)
                question_word = "Who" if token.pos_ == 'PRON' else "What"
            elif token.dep_ == 'advmod':
                # Adverbial modifier (when/where/how)
                if token.text in ('when', 'how long'):
                    question_word = "When"
                elif token.text in ('where', 'in what place'):
                    question_word = "Where"
                elif token.text in ('how', 'in what way'):
                    question_word = "How"
            elif token.dep_ == 'ROOT' and token.pos_ == 'VERB':
                # Special case for sentences starting with a verb (Do/Does/Did)
                if token.text.lower() in ('do', 'does'):
                    question_word = "Do" if token.text.lower() == 'do' else "Does"
                elif token.text.lower() == 'did':
                    question_word = "Did"
            elif token.text == "is" and i + 1 < len(doc) and doc[i + 1].pos_ in ("NOUN", "PROPN"):
                is_followed_by_noun = True
                # Special case for "is + noun phrase"
                question_word = "What"

            if question_word:
                break


        verb = None
        for token in doc:
            if token.pos_ in ('VERB', 'AUX'):
                verb = token.text
                break


        if question_word and verb:
            if is_followed_by_noun:
                question = f"{question_word} {verb} {doc[i + 1].text}?"  # Use noun phrase after "is"
            elif question_word in ('Do', 'Does', 'Did'):
                question = f"{question_word} {' '.join(token.text for token in doc[1:])}?"  # Handle sentences starting with a verb
            else:
                question = f"{question_word} {verb} {corrected_sentence.split(verb, 1)[1].strip()}?"
            return question
        else:
            return None

    # print(sentence)
    # Example usage
    question = convert_to_question(sentence)
    if question:
      print(f"Converted Question: {question}")
    else:
      print("Unable to convert the sentence into a question.")

    for sentence in sentences:
      question = convert_to_question(sentence)
      if question:
        print(f"Converted Question: {question}")
      else:
        del(question)
return {"result": "courseID"}


@app.route("/courseData", methods=["GET"])
def courseData():
    Course = {"name": "Operating Systems", "topics": ["registers", "busses"], "code": "OSX034"}
    Course["code"] = request.args.get("code")

    return json.dumps(Course)


if __name__ == "__main__":
    app.run(debug=True)
